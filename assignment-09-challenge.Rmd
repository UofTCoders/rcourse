---
title: "Challenge assignment"
output: html_notebook
---

*To submit this assignment, upload the full document on Quercus,
including the original questions, your code, and the output. Submit
your assignment as a knitted `.pdf` (prefered) or `.html` file.*


Part of being an effective scientist involves being able to solve problems you
have not encountered before. This is certainly true of programming as well,
where problems are typically solved by furious bouts Googling, reading
documentation, and trial and error of proposed solutions. In this assignment,
like previous ones, you will be evaluated on your ability to solve data
manipulation and analysis tasks. However, unlike previous assignments, some of
the solutions to the problems will require more research and effort on your
part. It may require the use of packages and techniques not explored in class,
but all problems are solveable, often with only a few lines of code. By now, you
should all have the terminology required to search for solutions to the problems
below. As with all programming problems, there are many possible ways to get the
answer to the problems below.

```{r messages = FALSE}
library(tidyverse)
library(reshape2)
```

1. Simpson's diversity index and bootstrapping (6 marks)

In lecture 12, we used data from the National Ecological Observatory Networkd on
the abundance and percent cover of plant species across sites in the Harvard
Forest from the year 2017. Run the code chunck below to read in the data if you
do not already have it.

```{r messages = FALSE}

neon_data <- "https://uoftcoders.github.io/rcourse/data/NEON_PlantPA_HARV_201707.csv"
download.file(neon_data, "NEON_PlantPA_HARV_201707.csv")
neon_data <- read_csv("NEON_PlantPA_HARV_201707.csv", 
                                col_names = TRUE)
```

    a. Using the raw NEON data, create a matrix with plant species as rows and sites
    as columns. The cell values should represent the abundance of each species at a
    given site. (1 mark)

```{r}
neon_filtered <- neon_data %>%
    # We only want rows with plant species and not 'otherVariables'
    dplyr::filter(divDataType == "plantSpecies") %>% 
    
    # To create a presence-absence matrix, we only need the taxonID 
    # (i.e. species) and the plotID (i.e. Site)
    dplyr::select(plotID, taxonID) 

# Create abundance matrix
abund_matrix <- dcast(neon_filtered, formula = taxonID ~ plotID, value.var = 'taxonID', fun.aggregate = length)
```

    b. Write a function that takes a single numeric vector as an argument and
    returns Simpson's Index of Diversity for the numeric vector. Test your
    function by computing Simpson's diversity index on the `test_vector` in the
    code chunk below. Be sure to report the Simpson's index for `test_vector` in
    your final assignment. As a reminder, I have included the formula for
    Simpson's index below:
    
$$D = 1 - \sum_{i = 1}^{s}(p_i)^2$$
    
    where `s` is the species richness (i.e. number of species) and `p_i` is the
    relative abundance of species _i_. A `D` value of 0 represents no diversity,
    and a D value of 1 represent infinite diversity. (1 mark)

```{r}
test_vector <- c(0, 1, 0, 5, 0, 1, 0, 4, 3, 0, 0, 0, 0, 1, 4, 0, 5, 0, 3, 0, 11, 2, 19, 0, 11, 0, 0, 0, 0, 0)

simpson_index <- function(vector){

    # Total sumber of individuals
    N <- sum(vector)
    
    # Squared relative abundance
    p_squared <- (vector / N)^2
    
    # Calculate 1 minus Simpson's index
    # 0 = No diversity, 1 = Infinite diversity
    simpsons <- 1 - sum(p_squared)
    
    return(simpsons)
}

# Run function
simpson_index(test_vector)
```

    c. In lecture 12, we discussed how resampling techniques can be used to
    conduct hypothesis tests (i.e., permutation tests) by comparing an observed
    population parameter (e.g., mean, median) to a null distribution of that
    parameter generated by resampling your observed data _without_ replacement
    many times. Resampling can additionally be used to generate confidence
    intervals around a population parameter (e.g., mean median, slope) or other
    statistic (e.g., C-score) using a technique known as _bootstrapping_.
    Bootstrapping allows us to estimate the true distribution of a statistic in
    cases where it is unknown, which we can use to estimate our uncertainty
    (e.g., Standard Error, Confidence Intervals) in a population parameter.
    Importantly, this applies _regardless of the shape of the distribution_,
    although some adjustments often have to be made for strongly skewed
    distributions. While there are a few different types of bootstrapped
    confidence intervals (e.g., bias-corrected and accelerated, _t_ with
    bootstrap), in this exercise, you will write a function that calculates the
    simple 95% percentile bootstrapped confidence interval from a given numeric
    vector. Your function should have the following properties:

        1. It should take in two arguments: A numeric vector and an integer
        representing the number of iterations 
        2. It should return a data frame with two columns: The lower and upper
        quantiles of the distribution, representing the 2.5 and 97.5
        percentiles, respectively (**hint:** The `quantile()` function).
        
    Write the function as described above. How does the bootstrap differ from a
    permutation test (note: you don't need code here, just tell me in words).
    Set a seed of 42 and test your function on the `test_vector` from part (b).
    (1.5 marks)

```{r}
# Bootstrapping involves sampling with replacement

set.seed(42)
boot_ci_simpsons <- function(vector, nreps){
    
    simpsons_indices <- c()
    
    for(i in 1:nreps){
        
        reshuffled <- sample(vector, size = length(vector), replace = TRUE)
    
        simpsons_indices[i] <- simpson_index(reshuffled)
    }
    
    quantiles <- quantile(simpsons_indices, c(0.025, 0.975))
    
    quantile_df <- data.frame(lower = quantiles['2.5%'], upper = quantiles['97.5%'])
    
    return(quantile_df)
    
}

quantiles <- boot_ci_simpsons(test_vector, nreps = 1000)
# hist(simpsons_indices)
# print(c(mean(simpsons_indices), median(simpsons_indices)))
quantiles
```

    d. Use your functions defined in (b) and (c) to estimate the Simpson's
    diversity index and corresponding 95% bootstrapped confidence intervals
    around the Simpson's index for each of the sites in your dataframe from (a).
    Your answer should be a single dataframe with four columns: `site`,
    `simpson`, `lower`, and `upper`. Points are awarded for conciseness of the
    code. (**Hint:** The most concise answer will likely make use of the `purrr`
    package, which is part of the `tidyverse`). (1.5 marks)

```{r}
set.seed(43)

# One solution
simp_df <- abund_matrix %>% 
    select_if(is.numeric) %>% 
    purrr::map_dfr(~data.frame(simpsons = simpson_index(.),
                               boot_ci_simpsons(., nreps = 1000)), 
                   .id = "site") 

# Another solution
col_list <- abund_matrix %>% 
    select_if(is.numeric) %>% 
    as.list()

simp_df <- purrr::map_dfr(col_list, simpson_index, .id = "site") %>% 
    gather(site, simpson) %>% 
    left_join(purrr::map_dfr(col_list, boot_ci_simpsons, nreps = 1000, .id = "site"), by = "site")
```

    e. Using the dataframe from (d), plot the Simpson's index (y-axis) for each
    of the sites (x-axis) as a single point surrounded by its lower and upper
    95% CIs. Order the x-axis from lowest to highest Simpson's index. (1 mark)

```{r}
ggplot(data = simp_df, aes(x = reorder(site, simpson), y = simpson)) +
    geom_point(size = 2, color = "black") + 
    geom_errorbar(aes(ymax = upper, ymin = lower), width = 0.15, colour = "black") +
    theme_classic()
```

2. In assignment 3, we explored a dataset containing changes in yearly plant
biomass in Abisko National Park, Sweden. In this question, we will use `ggplot2` to
reproduce a figure in the original paper (Olofsson et al, 2013; [link](https://royalsocietypublishing.org/doi/full/10.1098/rstb.2012.0486)). 

You should still have the dataset from when you completed assignment 3, but
if not, run the code chunk below to download it.

```{r}
plant_biomass_url <- 'https://raw.githubusercontent.com/UofTCoders/rcourse/master/data/plant-biomass-preprocess.csv'
download.file(plant_biomass_url, 'plant-biomass-preprocess.csv')
plant_biomass <- read_csv('plant-biomass-preprocess.csv')
```

Reproduce figure 4 from the paper using `ggplot2`. Pay close attention to the
overall structure of the figure, the scale on the axes, and so on. The colors of
the points do not need to be the exact same colors as those in the figure, but
they should be sufficiently close. _(Note: you can ignore the SEM points, and
the 'look' of your axes does not have to match the figure exactly. The species
names also not have to be included in the body of the plot as long as they are
visible in some form.)_

3. Use the built-in R dataset `iris`, for this question. 

     a. Test the relationship between sepal length and sepal width _for each
     species_ using linear models. Set sepal width as the response and sepal
     length as the predictor. Output a single data frame containing the beta
     estimate and p-value associated with the predictor for each of the three
     models, and also make sure to include a column called 'species' in the
     final data frame. Do not include the intercepts. _(Hint: the most efficient
     answer here will make use of the `purrr` and `broom` packages.)_
     
```{r}
iris %>% 
    split(.$Species) %>% 
    map_dfr(
        ~ broom::tidy(lm(Sepal.Width ~ Sepal.Length, data = .)), .id = 'species'
    ) %>% 
    filter(term != '(Intercept)') %>% 
    select(species, term, estimate, p.value)
```
     
    b. Use `ggplot2` to plot a scatter plot of sepal width by sepal length,
    coloured by species. Plot the three linear fits as well, also coloured by
    species. Below your code, comment on how the estimate values from your
    linear models above correspond to the plotted fits.
    
```{r}
iris %>% 
    ggplot(aes(x = Sepal.Length, y = Sepal.Width, color = Species)) +
    geom_point() +
    geom_smooth(method = 'lm', se = FALSE) +
    theme_classic()
```

3. The Canadian lynx population cycle (3 marks)

    The Canadian lynx experiences large periodic changes in its population 
    size over a timescale of several years. This is thought to be driven by 
    oscillations in the population size of the snowshoe hare, the primary food 
    source for the lynx. Read more about the lynx population cycle on this 
    [Northwest Territories website](https://www.enr.gov.nt.ca/en/services/lynx/lynx-snowshoe-hare-cycle).
    
    R has a built-in dataset called `lynx` which contains annual population 
    measurements for the Canadian lynx as a time series. 

(a) Plot `lynx` vs. time in years using either `ggplot` or `qplot`. 
    Plot points (`geom_point`) and a connecting line (`geom_line`). 
    Create a time series that starts at 0 and ends at the total number of 
    years in the dataset (total years $= 1934-1821$).
    By eye, estimate the time between peaks in the population. (0.5 marks)

```{r}
years = seq(0, 1934-1821, by = 1)
qplot(x = years, y = lynx) +
  geom_line()

# optional: make data frame 
df = data.frame(lynx)
df["time"] = years

# the time between peaks is about 10 years. 
```

(b) Define a function called `sine_model` that takes 5 arguments: a vector of years
    for the x-axis and four parameters (amplitude, period, phase, and offset). 
    Recall the general formula for a sine wave:
    $$y = A \text{sin}(kx - b) + c$$
    where $k = 2\pi / T$, $T$ is the period or length of time between peaks,
    $A$ is the amplitude, $b$ is the phase, and $c$ is the offset.
    Using a value of $A = c = 1700$ for both the amplitude and offset and a value of 
    $b = 2.75$ for the phase, plot the lynx data as before and add a sine curve 
    using your guess of the timescale from part (a) for the period.
    Use a colour other than black to plot the sine wave. 
    Note that the x axis must start at 0 in order for the offset of $2.75$
    to match the data. (1 mark)

```{r}
sine_model <- function(x, amplitude, period, phase, offset) {
  return(amplitude*sin(2*pi/period*x + phase) + offset)
}

guess_curve <- sine_model(years, 1700, 10, -2.75, 1700)

qplot(x = years, y = lynx) +
  geom_line() +
  geom_line(aes(x = years, y = guess_curve, colour = 'red'))
```

(c) Use least-squares fitting to refine your estimate of the lynx cycle length. (1.5 marks)
    - Make a range of values for the period that span your guess from part (a).
    - Use the `sapply` function to calculate a predicted dataset using a sine model. 
    Calculate the sum of the difference (*residuals*) between the lynx data and
    your prediction, then return the sum of the residuals squared.
    - Plot the sum of the residuals squared vs. the range of period values. By eye,
    what is the minimum of this curve? What value of the period gives the best fit?
    - Use the function `which` to extract the period value that gives the best fit. 
    What is your calculated length of the lynx population cycle?
    
```{r}
# Make a range of b parameter values to try
lambda_vals <- seq(9, 10, by = 0.01)
amplitude <- 1700
offset <- 1700
b <- -2.75

# use the function 'sapply' to loop over b_vals list
resids_sq <- map_dbl(lambda_vals, function(lambda) {
    prediction <- amplitude*sin(2*pi/lambda*years + b) + offset
    residuals <- prediction - lynx
    sum(residuals^2)
})

```

```{r}
qplot(lambda_vals, resids_sq)

# by eye, the best fit is around 9.62
```

```{r}
best_fit <- which(resids_sq == min(resids_sq))
l_fit <- lambda_vals[best_fit] 
l_fit
```

(d) Plot the lynx data again and plot your best fit curve on top. 
    Does your estimate of the cycle length match the literature?
    Why or why not? (Find and cite a resource that gives an estimate
    of the lynx population cycle.)

```{r}
fit_curve <- sine_model(years, 1700, l_fit, -2.75, 1700)

qplot(x = years, y = lynx) +
  geom_line() +
  geom_line(aes(x = years, y = fit_curve, colour = 'red'))
```
